---
layout: archive

permalink: /thoughts/attention
author_profile: true
redirect_from:
  - /attention
---


{% include base_path %}


Since its debut in Neural Machine Translation(NMT), attention mechanism has been witnessed widely and frequently in various studies of Natural Language Processing(NLP) and Computer Vision(CV). As I am unfamiliar with CV, here I will only talk a bit about what attention is by intuition and in implementation, how it works and hopefully why it proves useful.
